from __future__ import annotations

import os
from datetime import datetime, timedelta
import json

import numpy as np
import pandas as pd
from typing import Optional

from sklearn.ensemble import IsolationForest

import streamlit as st
import plotly.graph_objects as go

# --- Optional deps (graceful fallback)
try:
    from scipy.stats import ttest_ind, mannwhitneyu
    HAS_SCIPY = True
except Exception:
    HAS_SCIPY = False

try:
    from streamlit_autorefresh import st_autorefresh
    HAS_AUTOREFRESH = True
except Exception:
    HAS_AUTOREFRESH = False

# Add import for OpenAI API
try:
    from openai import OpenAI
    HAS_OPENAI = True
except Exception:
    HAS_OPENAI = False


from services.io import (
    load_and_clean_data,
    aggregate_daily_data,
    aggregate_daily_data_by_region,
    load_accident_records,
)
from services.forecast import (
    arima_forecast_with_grid_search,
    knn_forecast_counterfactual,
    fit_and_extrapolate,
)
from services.strategy import (
    evaluate_strategy_effectiveness,
    generate_output_and_recommendations,
)
from services.metrics import evaluate_models

try:
    from ui_sections import (
        render_overview,
        render_forecast,
        render_model_eval,
        render_strategy_eval,
        render_hotspot,
    )
except Exception:  # pragma: no cover - fallback to inline logic
    render_overview = None
    render_forecast = None
    render_model_eval = None
    render_strategy_eval = None
    render_hotspot = None

def detect_anomalies(series: pd.Series, contamination: float = 0.1):
    series = series.asfreq('D').fillna(0)
    iso = IsolationForest(n_estimators=50, contamination=contamination, random_state=42, n_jobs=-1)
    yhat = iso.fit_predict(series.values.reshape(-1, 1))
    anomaly_mask = (yhat == -1)
    anomaly_indices = series.index[anomaly_mask]

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=series.index, y=series.values, mode='lines', name='Accident Count'))
    fig.add_trace(go.Scatter(x=anomaly_indices, y=series.loc[anomaly_indices], mode='markers',
                             marker=dict(color='red', size=10), name='Anomalies'))
    fig.update_layout(title="Anomaly Detection in Accident Count",
                      xaxis_title="Date", yaxis_title="Count")
    return anomaly_indices, fig




def intervention_model(series: pd.Series,
                       intervention_date: pd.Timestamp,
                       intervention_type: str = 'persistent',
                       effect_type: str = 'sudden',
                       omega: float = 0.5,
                       decay: float = 10.0,
                       lag: int = 0):
    series = series.asfreq('D').fillna(0)
    intervention_date = pd.to_datetime(intervention_date)
    Z_t = pd.Series(0.0, index=series.index)
    if intervention_type == 'persistent':
        Z_t.loc[intervention_date:] = 1.0
    else:
        post_len = len(Z_t.loc[intervention_date:])
        Z_t.loc[intervention_date:] = np.exp(-np.arange(post_len) / decay)
    if effect_type == 'gradual':
        Z_t = Z_t * np.linspace(0, 1, len(Z_t))
    Z_t = Z_t.shift(lag).fillna(0)
    Y_t = series + omega * Z_t
    return Y_t, Z_t


# =======================
# 3. UI Helpers
# =======================

def compute_kpis(df_city: pd.DataFrame, arima_df: Optional[pd.DataFrame],
                 today: pd.Timestamp, window:int=30):
    # ä»Šæ—¥/æ˜¨æ—¥
    today_date = pd.to_datetime(today.date())
    yesterday = today_date - pd.Timedelta(days=1)
    this_week_start = today_date - pd.Timedelta(days=today_date.weekday())  # å‘¨ä¸€
    last_week_start = this_week_start - pd.Timedelta(days=7)
    this_week_end = today_date

    today_cnt = int(df_city['accident_count'].get(today_date, 0))
    yest_cnt = int(df_city['accident_count'].get(yesterday, 0))
    wow = (today_cnt - yest_cnt) / yest_cnt if yest_cnt > 0 else 0.0

    this_week = df_city.loc[this_week_start:this_week_end]['accident_count'].sum()
    last_week = df_city.loc[last_week_start:last_week_start + pd.Timedelta(days=(this_week_end - this_week_start).days)]['accident_count'].sum()
    yoy = (this_week - last_week) / last_week if last_week > 0 else 0.0

    # é¢„æµ‹åå·®ï¼ˆè¿‘7å¤©ï¼‰
    forecast_bias = None
    if arima_df is not None:
        recent = df_city.index.max() - pd.Timedelta(days=6)
        actual = df_city.loc[recent:df_city.index.max(), 'accident_count']
        fcst = arima_df['forecast'].reindex(actual.index).fillna(method='ffill')
        denom = fcst.replace(0, np.nan)
        bias = (np.abs(actual - fcst) / denom).dropna()
        forecast_bias = float(bias.mean()) if len(bias) else None

    # ç­–ç•¥è¦†ç›–ï¼ˆè¿‘30å¤©ï¼‰
    last_window = df_city.index.max() - pd.Timedelta(days=window-1)
    strat_days = df_city.loc[last_window:, 'strategy_type'].apply(lambda x: len(x) > 0).sum()
    coverage = strat_days / window

    # ä¸Šçº¿ç­–ç•¥æ•°ï¼ˆå»é‡ï¼‰
    active_strats = set(s for lst in df_city.loc[last_window:, 'strategy_type'] for s in lst)
    active_count = len(active_strats)

    # è¿‘30å¤©å®‰å…¨ç­‰çº§ï¼ˆç”¨ generate_output_and_recommendations é‡Œ best çš„ç­‰çº§ï¼‰
    # è¿™é‡Œåªå–æœ€è¿‘å‡ºç°è¿‡çš„ç­–ç•¥åšè¯„ä¼°
    strategies = sorted(active_strats)
    safety_state = 'â€”'
    if strategies:
        res, _ = generate_output_and_recommendations(df_city.loc[last_window:], strategies, region='å…¨å¸‚', horizon=min(30, len(df_city.loc[last_window:])))
        if res:
            # å–é€‚é…åº¦æœ€é«˜çš„ç­–ç•¥çš„å®‰å…¨ç­‰çº§
            best = max(res, key=lambda k: res[k]['adaptability'])
            safety_state = res[best]['safety_state']

    return {
        'today_cnt': today_cnt,
        'wow': wow,
        'this_week': int(this_week),
        'yoy': yoy,
        'forecast_bias': forecast_bias,
        'active_count': active_count,
        'coverage': coverage,
        'safety_state': safety_state
    }


def significance_test(pre: pd.Series, post: pd.Series):
    pre = pre.dropna(); post = post.dropna()
    if len(pre) < 3 or len(post) < 3:
        return None, None
    if HAS_SCIPY:
        try:
            stat, p = ttest_ind(pre, post, equal_var=False)
        except Exception:
            stat, p = mannwhitneyu(pre, post, alternative='two-sided')
        return float(stat), float(p)
    return None, None


def save_fig_as_html(fig, filename):
    html = fig.to_html(full_html=True, include_plotlyjs='cdn')
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html)
    return filename


# =======================
# 4. App
# =======================


# =======================
# 4. App
# =======================
def run_streamlit_app():
    # Must be the first Streamlit command
    st.set_page_config(page_title="Traffic Safety Analysis", layout="wide")
    st.title("ğŸš¦ Traffic Safety Intervention Analysis System")

    # Sidebar â€” Upload & Global Filters & Auto Refresh
    st.sidebar.header("æ•°æ®ä¸ç­›é€‰")

    default_min_date = pd.to_datetime('2022-01-01').date()
    default_max_date = pd.to_datetime('2022-12-31').date()

    def clamp_date_range(requested, minimum, maximum):
        """Ensure the requested tuple stays within [minimum, maximum]."""
        if not isinstance(requested, (list, tuple)):
            requested = (requested, requested)
        start, end = requested
        if start > end:
            start, end = end, start
        if end < minimum or start > maximum:
            return minimum, maximum
        start = max(minimum, start)
        end = min(maximum, end)
        return start, end

    # Initialize session state to store processed data (before rendering controls)
    if 'processed_data' not in st.session_state:
        st.session_state['processed_data'] = {
            'combined_city': None,
            'combined_by_region': None,
            'accident_data': None,
            'accident_records': None,
            'strategy_data': None,
            'all_regions': ["å…¨å¸‚"],
            'all_strategy_types': [],
            'min_date': default_min_date,
            'max_date': default_max_date,
            'region_sel': "å…¨å¸‚",
            'date_range': (default_min_date, default_max_date),
            'strat_filter': [],
            'accident_source_name': None,
        }

    sidebar_state = st.session_state['processed_data']

    available_regions = sidebar_state['all_regions'] if sidebar_state['all_regions'] else ["å…¨å¸‚"]
    current_region = sidebar_state['region_sel'] if sidebar_state['region_sel'] in available_regions else available_regions[0]
    available_strategies = sidebar_state['all_strategy_types']
    current_strategies = [s for s in sidebar_state['strat_filter'] if s in available_strategies]

    min_date = sidebar_state['min_date']
    max_date = sidebar_state['max_date']
    raw_start, raw_end = sidebar_state['date_range']
    start_default = max(min_date, min(raw_start, max_date))
    end_default = max(start_default, min(raw_end, max_date))
    
    # Create a form for data inputs to batch updates
    with st.sidebar.form(key="data_input_form"):
        accident_file = st.file_uploader("ä¸Šä¼ äº‹æ•…æ•°æ® (Excel)", type=['xlsx'])
        strategy_file = st.file_uploader("ä¸Šä¼ äº¤é€šç­–ç•¥æ•°æ® (Excel)", type=['xlsx'])

        # Global filters
        st.markdown("---")
        st.subheader("å…¨å±€ç­›é€‰å™¨")
        region_sel = st.selectbox(
            "åŒºåŸŸ",
            options=available_regions,
            index=available_regions.index(current_region),
            key="region_select",
        )
        date_range = st.date_input(
            "æ—¶é—´èŒƒå›´",
            value=(start_default, end_default),
            min_value=min_date,
            max_value=max_date,
        )
        strat_filter = st.multiselect(
            "ç­–ç•¥ç±»å‹ï¼ˆè¿‡æ»¤ï¼‰",
            options=available_strategies,
            default=current_strategies,
            help="ä¸ºç©ºè¡¨ç¤ºä¸è¿‡æ»¤ç­–ç•¥ï¼›é€‰æ‹©åä»…ä¿ç•™å½“å¤©åŒ…å«æ‰€é€‰ç­–ç•¥çš„æ—¥æœŸ",
        )
        
        # Apply button for data loading and filtering
        apply_button = st.form_submit_button("åº”ç”¨æ•°æ®ä¸ç­›é€‰")

    # Auto-refresh controls (outside the form, as itâ€™s independent)
    st.sidebar.markdown("---")
    st.sidebar.subheader("å®æ—¶åˆ·æ–°")
    auto = st.sidebar.checkbox("è‡ªåŠ¨åˆ·æ–°", value=False, help="å¯ç”¨åå°†æŒ‰é—´éš”è‡ªåŠ¨åˆ·æ–°é¡µé¢")
    interval = st.sidebar.number_input("åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰", min_value=5, max_value=600, value=30, step=5)
    if auto and HAS_AUTOREFRESH:
        st_autorefresh(interval=int(interval*1000), key="autorefresh")
    elif auto and not HAS_AUTOREFRESH:
        st.sidebar.info("æœªå®‰è£… `streamlit-autorefresh`ï¼Œè¯·ä½¿ç”¨ä¸Šæ–¹â€œé‡æ–°è¿è¡Œâ€æŒ‰é’®æˆ–å…³é—­å†å¼€å¯æ­¤å¼€å…³ã€‚")

    # Add OpenAI API key input in sidebar
    st.sidebar.markdown("---")
    st.sidebar.subheader("AI API é…ç½®")
    openai_api_key = st.sidebar.text_input("AI API Key", value='sk-sXY934yPqjh7YKKC08380b198fEb47308cDa09BeE23d9c8a', type="password", help="ç”¨äº AI åˆ†æç»“æœçš„ API å¯†é’¥")
    open_ai_base_url = st.sidebar.text_input("AI Base Url", value='https://aihubmix.com/v1', type='default')

    # Process data only when Apply button is clicked
    if apply_button and accident_file and strategy_file:
        with st.spinner("æ•°æ®è½½å…¥ä¸­â€¦"):
            # Load and clean data
            accident_records = load_accident_records(accident_file, require_location=True)
            accident_data, strategy_data = load_and_clean_data(accident_file, strategy_file)
            combined_city = aggregate_daily_data(accident_data, strategy_data)
            combined_by_region = aggregate_daily_data_by_region(accident_data, strategy_data)

            # Update available options for filters
            all_regions = ["å…¨å¸‚"] + sorted(accident_data['region'].unique().tolist())
            all_strategy_types = sorted({s for lst in combined_city['strategy_type'] for s in lst})
            min_date = combined_city.index.min().date()
            max_date = combined_city.index.max().date()

            # Store processed data in session state
            sanitized_start, sanitized_end = clamp_date_range(date_range, min_date, max_date)
            st.session_state['processed_data'].update({
                'combined_city': combined_city,
                'combined_by_region': combined_by_region,
                'accident_data': accident_data,
                'accident_records': accident_records,
                'strategy_data': strategy_data,
                'all_regions': all_regions,
                'all_strategy_types': all_strategy_types,
                'min_date': min_date,
                'max_date': max_date,
                'region_sel': region_sel,
                'date_range': (sanitized_start, sanitized_end),
                'strat_filter': strat_filter,
                'accident_source_name': getattr(accident_file, "name", "äº‹æ•…æ•°æ®.xlsx"),
            })

    sanitized_start, sanitized_end = clamp_date_range(date_range, min_date, max_date)

    # Persist the latest sidebar selections for display and downstream filtering
    st.session_state['processed_data']['region_sel'] = region_sel
    st.session_state['processed_data']['date_range'] = (sanitized_start, sanitized_end)
    st.session_state['processed_data']['strat_filter'] = strat_filter

    # Retrieve data from session state
    combined_city = st.session_state['processed_data']['combined_city']
    combined_by_region = st.session_state['processed_data']['combined_by_region']
    accident_data = st.session_state['processed_data']['accident_data']
    accident_records = st.session_state['processed_data']['accident_records']
    strategy_data = st.session_state['processed_data']['strategy_data']
    all_regions = st.session_state['processed_data']['all_regions']
    all_strategy_types = st.session_state['processed_data']['all_strategy_types']
    min_date = st.session_state['processed_data']['min_date']
    max_date = st.session_state['processed_data']['max_date']
    region_sel = st.session_state['processed_data']['region_sel']
    date_range = st.session_state['processed_data']['date_range']
    strat_filter = st.session_state['processed_data']['strat_filter']
    accident_source_name = st.session_state['processed_data']['accident_source_name']

    # Update selectbox and multiselect options dynamically (outside the form for display)
    st.sidebar.markdown("---")
    st.sidebar.subheader("å½“å‰ç­›é€‰çŠ¶æ€")
    st.sidebar.write(f"åŒºåŸŸ: {region_sel}")
    st.sidebar.write(f"æ—¶é—´èŒƒå›´: {date_range[0]} è‡³ {date_range[1]}")
    st.sidebar.write(f"ç­–ç•¥ç±»å‹: {', '.join(strat_filter) or 'æ— '}")

    # Proceed only if data is available
    if combined_city is not None and combined_by_region is not None:
        start_dt = pd.to_datetime(date_range[0])
        end_dt = pd.to_datetime(date_range[1])
        if region_sel == "å…¨å¸‚":
            base = combined_city.loc[start_dt:end_dt].copy()
        else:
            block = combined_by_region.xs(region_sel, level='region').copy()
            base = block.loc[start_dt:end_dt]
        if strat_filter:
            mask = base['strategy_type'].apply(lambda x: any(s in x for s in strat_filter))
            base = base[mask]

        # Last refresh info
        if 'last_refresh' not in st.session_state:
            st.session_state['last_refresh'] = datetime.now()
        last_refresh = st.session_state['last_refresh']

        # Compute ARIMA for KPI bias
        arima_df = None
        try:
            arima_df = arima_forecast_with_grid_search(
                base['accident_count'], base.index.max() + pd.Timedelta(days=1), horizon=7
            )
        except Exception:
            pass

        # KPI Overview
        kpi = compute_kpis(base, arima_df, today=pd.Timestamp('2022-12-01'))
        c1, c2, c3, c4, c5, c6 = st.columns(6)
        c1.metric("ä»Šæ—¥äº‹æ•…æ•°", f"{kpi['today_cnt']}", f"{kpi['wow']*100:.1f}% ç¯æ¯”")
        c2.metric("æœ¬å‘¨äº‹æ•…æ•°", f"{kpi['this_week']}", f"{kpi['yoy']*100:.1f}% åŒæ¯”")
        c3.metric("è¿‘7å¤©é¢„æµ‹åå·®", ("{:.1f}%".format(kpi['forecast_bias']*100) if kpi['forecast_bias'] is not None else "â€”"))
        c4.metric("è¿‘30å¤©ç­–ç•¥æ•°", f"{kpi['active_count']}")
        c5.metric("è¿‘30å¤©ç­–ç•¥è¦†ç›–ç‡", f"{kpi['coverage']*100:.1f}%")
        c6.metric("è¿‘30å¤©å®‰å…¨ç­‰çº§", kpi['safety_state'])

        # Top-right meta
        meta_col1, meta_col2 = st.columns([4, 1])
        with meta_col2:
            st.caption(f"ğŸ•’ æœ€è¿‘åˆ·æ–°ï¼š{last_refresh.strftime('%Y-%m-%d %H:%M:%S')}")

        tab_labels = [
            "ğŸ  æ€»è§ˆ",
            "ğŸ“ äº‹æ•…çƒ­ç‚¹",
            "ğŸ” AI åˆ†æ",
            "ğŸ“ˆ é¢„æµ‹æ¨¡å‹",
            "ğŸ“Š æ¨¡å‹è¯„ä¼°",
            "âš ï¸ å¼‚å¸¸æ£€æµ‹",
            "ğŸ“ ç­–ç•¥è¯„ä¼°",
            "âš–ï¸ ç­–ç•¥å¯¹æ¯”",
            "ğŸ§ª æƒ…æ™¯æ¨¡æ‹Ÿ",
        ]
        default_tab = st.session_state.get("active_tab", tab_labels[0])
        if default_tab not in tab_labels:
            default_tab = tab_labels[0]
        selected_tab = st.radio(
            "åŠŸèƒ½åˆ†åŒº",
            tab_labels,
            index=tab_labels.index(default_tab),
            horizontal=True,
            label_visibility="collapsed",
        )
        st.session_state["active_tab"] = selected_tab


        if selected_tab == "ğŸ  æ€»è§ˆ":
            if render_overview is not None:
                render_overview(base, region_sel, start_dt, end_dt, strat_filter)
            else:
                st.warning("æ¦‚è§ˆæ¨¡å—æœªèƒ½åŠ è½½ï¼Œè¯·æ£€æŸ¥ `ui_sections/overview.py`ã€‚")

        elif selected_tab == "ğŸ“ äº‹æ•…çƒ­ç‚¹":
            if render_hotspot is not None:
                render_hotspot(accident_records, accident_source_name)
            else:
                st.warning("äº‹æ•…çƒ­ç‚¹æ¨¡å—æœªèƒ½åŠ è½½ï¼Œè¯·æ£€æŸ¥ `ui_sections/hotspot.py`ã€‚")

        elif selected_tab == "ğŸ” AI åˆ†æ":
            from openai import OpenAI
            st.subheader("AI æ•°æ®åˆ†æä¸æ”¹è¿›å»ºè®®")
            if not HAS_OPENAI:
                st.warning("æœªå®‰è£… `openai` åº“ã€‚è¯·å®‰è£…åé‡è¯•ã€‚")
            elif not openai_api_key:
                st.info("è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ OpenAI API Key ä»¥å¯ç”¨ AI åˆ†æã€‚")
            else:
                if all_strategy_types:
                    # Generate results if not already
                    results, recommendation = generate_output_and_recommendations(base, all_strategy_types,
                                                                                 region=region_sel if region_sel != 'å…¨å¸‚' else 'å…¨å¸‚')
                    df_res = pd.DataFrame(results).T
                    kpi_json = json.dumps(kpi, ensure_ascii=False, indent=2)
                    results_json = df_res.to_json(orient="records", force_ascii=False)
                    recommendation_text = recommendation

                    # Prepare data to send
                    data_to_analyze = {
                        "kpis": kpi_json,
                        "strategy_results": results_json,
                        "recommendation": recommendation_text
                    }
                    data_str = json.dumps(data_to_analyze, ensure_ascii=False)

                    prompt = (
                        "ä½ æ˜¯ä¸€åèµ„æ·±äº¤é€šå®‰å…¨æ•°æ®åˆ†æé¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹ç»“æ„åŒ–æ•°æ®è¾“å‡ºä¸€ä»½ä¸“ä¸šæŠ¥å‘Šï¼Œéœ€åŒ…å«ï¼š\n"
                        "1. æ ¸å¿ƒæŒ‡æ ‡æ´å¯Ÿï¼šæŒ‰è¦ç‚¹æ€»ç»“äº‹æ•…è¶‹åŠ¿ã€æ˜¾è‘—æ³¢åŠ¨åŠå¯èƒ½åŸå› ã€‚\n"
                        "2. ç­–ç•¥ç»©æ•ˆè¯„ä¼°ï¼šå¯¹æ¯”ä¸»è¦ç­–ç•¥çš„ä¼˜åŠ¿ã€çŸ­æ¿ä¸é€‚ç”¨åœºæ™¯ã€‚\n"
                        "3. ä¼˜åŒ–å»ºè®®ï¼šä¸ºçŸ­æœŸï¼ˆ0-3ä¸ªæœˆï¼‰ã€ä¸­æœŸï¼ˆ3-12ä¸ªæœˆï¼‰ä¸é•¿æœŸï¼ˆ12ä¸ªæœˆä»¥ä¸Šï¼‰åˆ†åˆ«ç»™å‡º2-3æ¡å¯æ“ä½œæªæ–½ã€‚\n"
                        "è¯·ä¿æŒæ­£å¼è¯­æ°”ï¼Œå¼•ç”¨å…³é”®æ•°å€¼æ”¯æ’‘ç»“è®ºï¼Œå¹¶ç”¨æ¸…æ™°çš„å°èŠ‚æˆ–åˆ—è¡¨å‘ˆç°ã€‚\n"
                        f"æ•°æ®æ‘˜è¦ï¼š{data_str}\n"
                    )
                    if st.button("ä¸Šä¼ æ•°æ®è‡³ AI å¹¶è·å–åˆ†æ"):
                        if not openai_api_key.strip():
                            st.info("è¯·æä¾›æœ‰æ•ˆçš„ AI API Keyã€‚")
                        elif not open_ai_base_url.strip():
                            st.info("è¯·æä¾›å¯è®¿é—®çš„ AI Base Urlã€‚")
                        else:
                            try:
                                client = OpenAI(
                                        base_url=open_ai_base_url,
                                        # sk-xxxæ›¿æ¢ä¸ºè‡ªå·±çš„key
                                        api_key=openai_api_key
                                )
                                st.markdown("### AI åˆ†æç»“æœä¸æ”¹è¿›æ€è·¯")
                                placeholder = st.empty()
                                accumulated_response: list[str] = []
                                with st.spinner("AI æ­£åœ¨ç”Ÿæˆä¸“ä¸šæŠ¥å‘Šï¼Œè¯·ç¨å€™â€¦"):
                                    stream = client.chat.completions.create(
                                        model="gpt-5-mini",
                                        messages=[
                                            {
                                                "role": "system",
                                                "content": "You are a professional traffic safety analyst who writes concise, well-structured Chinese reports."
                                            },
                                            {"role": "user", "content": prompt},
                                        ],
                                        stream=True,
                                    )
                                    for chunk in stream:
                                        delta = chunk.choices[0].delta if chunk.choices else None
                                        piece = getattr(delta, "content", None) if delta else None
                                        if piece:
                                            accumulated_response.append(piece)
                                            placeholder.markdown("".join(accumulated_response), unsafe_allow_html=True)
                                final_text = "".join(accumulated_response)
                                if not final_text:
                                    placeholder.info("AI æœªè¿”å›å¯ç”¨å†…å®¹ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥å‡­æ®é…ç½®ã€‚")
                            except Exception as e:
                                st.error(f"è°ƒç”¨ OpenAI API å¤±è´¥ï¼š{str(e)}")
                else:
                    st.warning("æ²¡æœ‰ç­–ç•¥æ•°æ®å¯ä¾›åˆ†æã€‚")

                # Update refresh time
                st.session_state['last_refresh'] = datetime.now()

        elif selected_tab == "ğŸ“ˆ é¢„æµ‹æ¨¡å‹":
            if render_forecast is not None:
                render_forecast(base)
            else:
                st.subheader("å¤šæ¨¡å‹é¢„æµ‹æ¯”è¾ƒ")
                # ä½¿ç”¨è¡¨å•å°è£…äº¤äº’ç»„ä»¶
                with st.form(key="predict_form"):
                    # ç¼©çŸ­é»˜è®¤å›æº¯çª—å£ï¼Œæå‡é¦–æ¬¡æ¸²æŸ“é€Ÿåº¦
                    default_date = base.index.max() - pd.Timedelta(days=30) if len(base) else pd.Timestamp('2022-01-01')
                    selected_date = st.date_input("é€‰æ‹©å¹²é¢„æ—¥æœŸ / é¢„æµ‹èµ·ç‚¹", value=default_date)
                    horizon = st.number_input("é¢„æµ‹å¤©æ•°", min_value=7, max_value=90, value=30, step=1)
                    submit_predict = st.form_submit_button("åº”ç”¨é¢„æµ‹å‚æ•°")

                if submit_predict and len(base.loc[:pd.to_datetime(selected_date)]) >= 10:
                    first_date = pd.to_datetime(selected_date)
                    try:
                        train_series = base['accident_count'].loc[:first_date]
                        arima30 = arima_forecast_with_grid_search(
                            train_series,
                            start_date=first_date + pd.Timedelta(days=1),
                            horizon=horizon
                        )
                    except Exception as e:
                        st.warning(f"ARIMA è¿è¡Œå¤±è´¥ï¼š{e}")
                        arima30 = None

                    knn_pred, _ = knn_forecast_counterfactual(base['accident_count'],
                                                            first_date,
                                                            horizon=horizon)
                    glm_pred, svr_pred, residuals = fit_and_extrapolate(base['accident_count'],
                                                                        first_date,
                                                                        days=horizon)

                    fig_pred = go.Figure()
                    fig_pred.add_trace(go.Scatter(x=base.index, y=base['accident_count'],
                                                name="å®é™…", mode="lines"))
                    if arima30 is not None:
                        fig_pred.add_trace(go.Scatter(x=arima30.index, y=arima30['forecast'],
                                                    name="ARIMA", mode="lines"))
                    if knn_pred is not None:
                        fig_pred.add_trace(go.Scatter(x=knn_pred.index, y=knn_pred,
                                                    name="KNN", mode="lines"))
                    if glm_pred is not None:
                        fig_pred.add_trace(go.Scatter(x=glm_pred.index, y=glm_pred,
                                                    name="GLM", mode="lines"))
                    if svr_pred is not None:
                        fig_pred.add_trace(go.Scatter(x=svr_pred.index, y=svr_pred,
                                                    name="SVR", mode="lines"))

                    fig_pred.update_layout(
                        title=f"å¤šæ¨¡å‹é¢„æµ‹æ¯”è¾ƒï¼ˆèµ·ç‚¹ï¼š{first_date.date()}ï¼Œé¢„æµ‹ {horizon} å¤©ï¼‰",
                        xaxis_title="æ—¥æœŸ", yaxis_title="äº‹æ•…æ•°"
                    )
                    st.plotly_chart(fig_pred, use_container_width=True)

                    col_dl1, col_dl2 = st.columns(2)
                    if arima30 is not None:
                        col_dl1.download_button("ä¸‹è½½ ARIMA é¢„æµ‹ CSV",
                                                data=arima30.to_csv().encode("utf-8-sig"),
                                                file_name="arima_forecast.csv",
                                                mime="text/csv")
                elif submit_predict:
                    st.info("âš ï¸ å¹²é¢„å‰æ•°æ®è¾ƒå°‘ï¼Œå¯èƒ½å½±å“æ‹Ÿåˆè´¨é‡ã€‚")
                else:
                    st.info("è¯·è®¾ç½®é¢„æµ‹å‚æ•°å¹¶ç‚¹å‡»â€œåº”ç”¨é¢„æµ‹å‚æ•°â€æŒ‰é’®ã€‚")

        # --- Tab 3: æ¨¡å‹è¯„ä¼°
        elif selected_tab == "ğŸ“Š æ¨¡å‹è¯„ä¼°":
            if render_model_eval is not None:
                render_model_eval(base)
            else:
                st.subheader("æ¨¡å‹é¢„æµ‹æ•ˆæœå¯¹æ¯”")
                with st.form(key="model_eval_form"):
                    horizon_sel = st.slider("è¯„ä¼°çª—å£ï¼ˆå¤©ï¼‰", 7, 60, 30, step=1)
                    submit_eval = st.form_submit_button("åº”ç”¨è¯„ä¼°å‚æ•°")

                if submit_eval:
                    try:
                        df_metrics = evaluate_models(base['accident_count'], horizon=horizon_sel)
                        st.dataframe(df_metrics, use_container_width=True)
                        best_model = df_metrics['RMSE'].idxmin()
                        st.success(f"è¿‡å» {horizon_sel} å¤©ä¸­ï¼ŒRMSE æœ€ä½çš„æ¨¡å‹æ˜¯ï¼š**{best_model}**")
                        st.download_button(
                            "ä¸‹è½½è¯„ä¼°ç»“æœ CSV",
                            data=df_metrics.to_csv().encode('utf-8-sig'),
                            file_name="model_evaluation.csv",
                            mime="text/csv"
                        )
                    except ValueError as err:
                        st.warning(str(err))
                else:
                    st.info("è¯·è®¾ç½®è¯„ä¼°çª—å£å¹¶ç‚¹å‡»â€œåº”ç”¨è¯„ä¼°å‚æ•°â€æŒ‰é’®ã€‚")

        # --- Tab 4: å¼‚å¸¸æ£€æµ‹
        elif selected_tab == "âš ï¸ å¼‚å¸¸æ£€æµ‹":
            anomalies, anomaly_fig = detect_anomalies(base['accident_count'])
            st.plotly_chart(anomaly_fig, use_container_width=True)
            st.write(f"æ£€æµ‹åˆ°å¼‚å¸¸ç‚¹ï¼š{len(anomalies)} ä¸ª")
            st.download_button("ä¸‹è½½å¼‚å¸¸æ—¥æœŸ CSV",
                            data=anomalies.to_series().to_csv(index=False).encode('utf-8-sig'),
                            file_name="anomalies.csv", mime="text/csv")

        # --- Tab 5: ç­–ç•¥è¯„ä¼°
        elif selected_tab == "ğŸ“ ç­–ç•¥è¯„ä¼°":
            if render_strategy_eval is not None:
                render_strategy_eval(base, all_strategy_types, region_sel)
            else:
                st.warning("ç­–ç•¥è¯„ä¼°æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ `ui_sections/strategy_eval.py`ã€‚")

        # --- Tab 6: ç­–ç•¥å¯¹æ¯”
        elif selected_tab == "âš–ï¸ ç­–ç•¥å¯¹æ¯”":
            def strategy_metrics(strategy):
                mask = base['strategy_type'].apply(lambda x: strategy in x)
                if not mask.any():
                    return None
                dt = mask[mask].index[0]
                glm_pred, svr_pred, residuals = fit_and_extrapolate(base['accident_count'], dt, days=30)
                if svr_pred is None:
                    return None
                actual_post = base['accident_count'].loc[dt:dt+pd.Timedelta(days=29)]
                pre = base['accident_count'].loc[dt-pd.Timedelta(days=30):dt-pd.Timedelta(days=1)]
                stat, p = significance_test(pre, actual_post)
                count_eff, sev_eff, (F1, F2), state = evaluate_strategy_effectiveness(
                    actual_series=base['accident_count'],
                    counterfactual_series=svr_pred,
                    severity_series=base['severity'],
                    strategy_date=dt, window=30
                )
                return {
                    "å¹²é¢„æ—¥": str(dt.date()),
                    "å‰30å¤©äº‹æ•…": int(pre.sum()),
                    "å30å¤©äº‹æ•…": int(actual_post.sum()),
                    "æ¯æ—¥å‡å€¼(å‰/å)": (float(pre.mean()), float(actual_post.mean())),
                    "tç»Ÿè®¡/på€¼": (stat, p),
                    "F1/F2": (float(F1), float(F2)),
                    "æœ‰æ•ˆå¤©æ•°è¿‡åŠ?": bool(count_eff),
                    "ä¸¥é‡åº¦ä¸‹é™?": bool(sev_eff),
                    "å®‰å…¨ç­‰çº§": state
                }
            if all_strategy_types:
                st.subheader("ç­–ç•¥å¯¹æ¯”")
                with st.form(key="strategy_compare_form"):
                    colA, colB = st.columns(2)
                    with colA:
                        sA = st.selectbox("ç­–ç•¥ A", options=all_strategy_types, key="stratA")
                    with colB:
                        sB = st.selectbox("ç­–ç•¥ B", options=[s for s in all_strategy_types if s != st.session_state.get("stratA")], key="stratB")
                    submit_compare = st.form_submit_button("åº”ç”¨ç­–ç•¥å¯¹æ¯”")

                if submit_compare:
                    mA = strategy_metrics(sA)
                    mB = strategy_metrics(sB)
                    if mA and mB:
                        show = pd.DataFrame({
                            "æŒ‡æ ‡": ["å¹²é¢„æ—¥", "å‰30å¤©äº‹æ•…", "å30å¤©äº‹æ•…", "æ¯æ—¥å‡å€¼(å‰)", "æ¯æ—¥å‡å€¼(å)", "tç»Ÿè®¡", "på€¼", "F1", "F2", "æœ‰æ•ˆå¤©æ•°è¿‡åŠ?", "ä¸¥é‡åº¦ä¸‹é™?", "å®‰å…¨ç­‰çº§"],
                            f"{sA}": [mA["å¹²é¢„æ—¥"], mA["å‰30å¤©äº‹æ•…"], mA["å30å¤©äº‹æ•…"],
                                    mA["æ¯æ—¥å‡å€¼(å‰/å)"][0], mA["æ¯æ—¥å‡å€¼(å‰/å)"][1],
                                    mA["tç»Ÿè®¡/på€¼"][0], mA["tç»Ÿè®¡/på€¼"][1],
                                    mA["F1/F2"][0], mA["F1/F2"][1],
                                    mA["æœ‰æ•ˆå¤©æ•°è¿‡åŠ?"], mA["ä¸¥é‡åº¦ä¸‹é™?"], mA["å®‰å…¨ç­‰çº§"]],
                            f"{sB}": [mB["å¹²é¢„æ—¥"], mB["å‰30å¤©äº‹æ•…"], mB["å30å¤©äº‹æ•…"],
                                    mB["æ¯æ—¥å‡å€¼(å‰/å)"][0], mB["æ¯æ—¥å‡å€¼(å‰/å)"][1],
                                    mB["tç»Ÿè®¡/på€¼"][0], mB["tç»Ÿè®¡/på€¼"][1],
                                    mB["F1/F2"][0], mB["F1/F2"][1],
                                    mB["æœ‰æ•ˆå¤©æ•°è¿‡åŠ?"], mB["ä¸¥é‡åº¦ä¸‹é™?"], mB["å®‰å…¨ç­‰çº§"]],
                        })
                        st.dataframe(show, use_container_width=True)
                        st.download_button("ä¸‹è½½å¯¹æ¯”è¡¨ CSV",
                                        data=show.to_csv(index=False).encode('utf-8-sig'),
                                        file_name="strategy_compare.csv", mime="text/csv")
                    else:
                        st.info("æ‰€é€‰ç­–ç•¥å¯èƒ½ç¼ºå°‘è¶³å¤Ÿçš„å¹²é¢„å‰æ•°æ®æˆ–æœªåœ¨å½“å‰è¿‡æ»¤èŒƒå›´å†…å‡ºç°ã€‚")
                else:
                    st.info("è¯·é€‰æ‹©ç­–ç•¥å¹¶ç‚¹å‡»â€œåº”ç”¨ç­–ç•¥å¯¹æ¯”â€æŒ‰é’®ã€‚")
            else:
                st.warning("æ²¡æœ‰ç­–ç•¥å¯ä¾›å¯¹æ¯”ã€‚")

        # --- Tab 7: æƒ…æ™¯æ¨¡æ‹Ÿ
        elif selected_tab == "ğŸ§ª æƒ…æ™¯æ¨¡æ‹Ÿ":
            st.subheader("æƒ…æ™¯æ¨¡æ‹Ÿ")
            st.write("é€‰æ‹©ä¸€ä¸ªæ—¥æœŸä¸ç­–ç•¥ï¼Œæ¨¡æ‹Ÿâ€œåœ¨è¯¥æ—¥æœŸä¸Šçº¿è¯¥ç­–ç•¥â€çš„å½±å“ï¼š")
            with st.form(key="simulation_form"):
                sim_date = st.date_input("æ¨¡æ‹Ÿç­–ç•¥ä¸Šçº¿æ—¥æœŸ", value=(base.index.max() - pd.Timedelta(days=14)))
                sim_strategy = st.selectbox("æ¨¡æ‹Ÿç­–ç•¥ç±»å‹", options=all_strategy_types or ["ç¤ºä¾‹ç­–ç•¥"])
                sim_days = st.slider("æ¨¡æ‹Ÿå¤©æ•°", 7, 60, 30)
                submit_simulation = st.form_submit_button("åº”ç”¨æ¨¡æ‹Ÿå‚æ•°")

            if submit_simulation:
                glm_pred, svr_pred, residuals = fit_and_extrapolate(base['accident_count'], pd.to_datetime(sim_date), days=sim_days)
                if svr_pred is None:
                    st.warning("å¹²é¢„å‰æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¨¡æ‹Ÿã€‚")
                else:
                    count_eff, sev_eff, (F1, F2), state = evaluate_strategy_effectiveness(
                        actual_series=base['accident_count'],
                        counterfactual_series=svr_pred,
                        severity_series=base['severity'],
                        strategy_date=pd.to_datetime(sim_date),
                        window=sim_days
                    )
                    fig_sim = go.Figure()
                    fig_sim.add_trace(go.Scatter(x=base.index, y=base['accident_count'], name='å®é™…', mode='lines'))
                    fig_sim.add_trace(go.Scatter(x=svr_pred.index, y=svr_pred, name='Counterfactual(SVR)', mode='lines'))
                    fig_sim.update_layout(title=f"æƒ…æ™¯æ¨¡æ‹Ÿï¼š{sim_strategy} è‡ª {sim_date} èµ·", xaxis_title="æ—¥æœŸ", yaxis_title="äº‹æ•…æ•°")
                    st.plotly_chart(fig_sim, use_container_width=True)

                    st.success(f"æ¨¡æ‹Ÿç»“æœï¼šF1={F1:.2f}, F2={F2:.2f}, ç­‰çº§={state}ï¼›"
                            f"{'äº‹æ•…æ•°åœ¨å¤šæ•°å¤©å°äºcounterfactual' if count_eff else 'æ•ˆæœä¸æ˜æ˜¾'}ï¼›"
                            f"{'ä¸¥é‡åº¦ä¸‹é™' if sev_eff else 'ä¸¥é‡åº¦æ— ä¸‹é™'}ã€‚")
                    st.download_button("ä¸‹è½½æ¨¡æ‹Ÿå›¾ HTML",
                                    data=open(save_fig_as_html(fig_sim, "simulation.html"), "rb").read(),
                                    file_name="simulation.html", mime="text/html")
            else:
                st.info("è¯·è®¾ç½®æ¨¡æ‹Ÿå‚æ•°å¹¶ç‚¹å‡»â€œåº”ç”¨æ¨¡æ‹Ÿå‚æ•°â€æŒ‰é’®ã€‚")

    else:
        st.info("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ äº‹æ•…æ•°æ®ä¸ç­–ç•¥æ•°æ®ï¼Œå¹¶ç‚¹å‡»â€œåº”ç”¨æ•°æ®ä¸ç­›é€‰â€æŒ‰é’®ã€‚")

if __name__ == "__main__":
    run_streamlit_app()
