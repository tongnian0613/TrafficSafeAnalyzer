# Usage Guide

TrafficSafeAnalyzer delivers accident analytics and decision support through a Streamlit interface. This guide walks through the daily workflow, expected inputs, and where to find generated artefacts.

## Start the app

1. Activate your virtual or conda environmentï¼ˆæˆ–åœ¨å®¹å™¨ä¸­è¿è¡Œï¼Œè§ä¸‹ï¼‰.
2. From the project root, run:

   ```bash
   streamlit run app.py
   ```

3. Open `http://localhost:8501`. Keep the terminal running while you work in the browser.

> ä½¿ç”¨ Dockerï¼Ÿè¿è¡Œ `docker build -t trafficsafeanalyzer .` ä¸ `docker run --rm -p 8501:8501 trafficsafeanalyzer` åï¼ŒåŒæ ·è®¿é—® `http://localhost:8501`ã€‚

## Load input data

Use the sidebar form labelled â€œæ•°æ®ä¸ç­›é€‰â€.

- **Accident data (`.xlsx`)** â€” columns should include at minimum:
  - `äº‹æ•…æ—¶é—´` (timestamp)
  - `æ‰€åœ¨è¡—é“` (region or district)
  - `äº‹æ•…ç±»å‹`
  - `äº‹æ•…æ•°`/`accident_count` (if absent, the loader aggregates counts)
- **Strategy data (`.xlsx`)** â€” include:
  - `å‘å¸ƒæ—¶é—´`
  - `äº¤é€šç­–ç•¥ç±»å‹`
  - optional descriptors such as `ç­–ç•¥åç§°`, `ç­–ç•¥å†…å®¹`
- Select the global filters (region, date window, strategy filter) and click `åº”ç”¨æ•°æ®ä¸ç­›é€‰`.
- Uploaded files are cached. Upload a new file or press â€œRerunâ€ to refresh after making edits.
- Sample datasets for rapid smoke testing live in `sample/äº‹æ•…/*.xlsx` (accidents) and `sample/äº¤é€šç­–ç•¥/*.xlsx` (strategies); copy them before making modifications.

> Tip: `services/io.py` performs validation; rows missing key columns are dropped with a warning in the Streamlit log.

## Navigate the workspace

- **ğŸ  æ€»è§ˆ (Overview)** â€” KPI cards, time-series plot, filtered table, and download buttons for HTML (`overview_series.html`), CSV (`filtered_view.csv`), and run metadata (`run_metadata.json`).
- **ğŸ“ˆ é¢„æµ‹æ¨¡å‹ (Forecast)** â€” choose an intervention date and horizon, compare ARIMA / KNN / GLM / SVR forecasts, and export `arima_forecast.csv`ï¼ˆæäº¤åç»“æœä¼šåœ¨åŒä¸€æ•°æ®é›†ä¸‹ä¿ç•™ï¼Œä¾¿äºè°ƒæ•´å…¶ä»–æ§ä»¶ï¼‰ã€‚
- **ğŸ“Š æ¨¡å‹è¯„ä¼° (Model evaluation)** â€” run rolling-window backtests, inspect RMSE/MAE/MAPE, and download `model_evaluation.csv`.
- **âš ï¸ å¼‚å¸¸æ£€æµ‹ (Anomaly detection)** â€” isolation forest marks outliers on the accident series; tweak contamination via the main page controls.
- **ğŸ“ ç­–ç•¥è¯„ä¼° (Strategy evaluation)** â€” Aggregates metrics per strategy type, recommends the best option, writes `strategy_evaluation_results.csv`, and updates `recommendation.txt`.
- **âš–ï¸ ç­–ç•¥å¯¹æ¯” (Strategy comparison)** â€” side-by-side metrics for selected strategies, useful for â€œwhat worked best last monthâ€ reviews.
- **ğŸ§ª æƒ…æ™¯æ¨¡æ‹Ÿ (Scenario simulation)** â€” apply intervention models (persistent/decay, lagged effects) to test potential roll-outs.
- **ğŸ” AI åˆ†æ** â€” é»˜è®¤ç¤ºä¾‹ API Key/Base URL å·²é¢„å¡«ï¼Œå¯ç›´æ¥ä½“éªŒï¼›å¦‚éœ€åˆ‡æ¢è‡ªæœ‰å‡­æ®ï¼Œå¯åœ¨ä¾§è¾¹æ æ›´æ–°åç”Ÿæˆæ´å¯Ÿï¼ˆè¿è¡Œæ—¶è¯»å–ï¼Œä¸ä¼šå†™å…¥ç£ç›˜ï¼‰ã€‚
- **ğŸ“ äº‹æ•…çƒ­ç‚¹ (Hotspot)** â€” reuse the already uploaded accident data to identify high-risk intersections and produce targeted mitigation ideas; no separate hotspot upload is required.

Each tab remembers the active filters from the sidebar so results stay consistent.

## Downloaded artefacts

Generated files are saved to the project root unless you override paths in the code:

- `overview_series.html`
- `filtered_view.csv`
- `run_metadata.json`
- `arima_forecast.csv`
- `model_evaluation.csv`
- `strategy_evaluation_results.csv`
- `recommendation.txt`

After a session, review and archive these outputs under `docs/` or a dated folder as needed.

## Operational tips

- **Auto refresh**: enable from the sidebar (requires `streamlit-autorefresh`). Set the interval in seconds for live dashboards.
- **Logging**: set `LOG_LEVEL=DEBUG` before launch to see detailed diagnostics in the terminal and Streamlit log.
- **Reset filters**: choose â€œå…¨å¸‚â€ and the full date span, then re-run the sidebar form.
- **Common warnings**:
  - *â€œæ•°æ®ä¸­æ²¡æœ‰æ£€æµ‹åˆ°ç­–ç•¥â€*: verify the strategy Excel file and column names.
  - *ARIMA failures*: shorten the horizon or ensure at least 10 historical data points before the intervention date.
  - *Hotspot data issues*: ensure the accident workbook includes `äº‹æ•…æ—¶é—´`, `æ‰€åœ¨è¡—é“`, `äº‹æ•…ç±»å‹`, and `äº‹æ•…å…·ä½“åœ°ç‚¹` so intersections can be resolved.

Need deeper integration or batch automation? Extract the core functions from `services/` and orchestrate them in a notebook or scheduled job.
