from __future__ import annotations

import json
from datetime import datetime

import plotly.express as px
import streamlit as st

from services.hotspot import (
    analyze_hotspot_frequency,
    calculate_hotspot_risk_score,
    generate_hotspot_strategies,
    prepare_hotspot_dataset,
    serialise_datetime_columns,
)


@st.cache_data(show_spinner=False)
def _prepare_hotspot_data(df):
    return prepare_hotspot_dataset(df)


def render_hotspot(accident_records, accident_source_name: str | None) -> None:
    st.header("ğŸ“ äº‹æ•…å¤šå‘è·¯å£åˆ†æ")
    st.markdown("ç‹¬ç«‹åˆ†æäº‹æ•…æ•°æ®ï¼Œè¯†åˆ«é«˜é£é™©è·¯å£å¹¶ç”Ÿæˆé’ˆå¯¹æ€§ç­–ç•¥ã€‚")

    if accident_records is None:
        st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ äº‹æ•…æ•°æ®å¹¶ç‚¹å‡»â€œåº”ç”¨æ•°æ®ä¸ç­›é€‰â€åå†æ‰§è¡Œçƒ­ç‚¹åˆ†æã€‚")
        st.markdown(
            """
            ### ğŸ“ æ”¯æŒçš„æ•°æ®æ ¼å¼è¦æ±‚ï¼š
            - **æ–‡ä»¶æ ¼å¼**ï¼šExcel (.xlsx)
            - **å¿…è¦å­—æ®µ**ï¼š
              - `äº‹æ•…æ—¶é—´`
              - `äº‹æ•…ç±»å‹`
              - `äº‹æ•…å…·ä½“åœ°ç‚¹`
              - `æ‰€åœ¨è¡—é“`
              - `é“è·¯ç±»å‹`
              - `è·¯å£è·¯æ®µç±»å‹`
            """
        )
        return

    with st.spinner("æ­£åœ¨å‡†å¤‡äº‹æ•…çƒ­ç‚¹æ•°æ®â€¦"):
        hotspot_data = _prepare_hotspot_data(accident_records)

    st.success(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼š{len(hotspot_data)} æ¡äº‹æ•…è®°å½•")

    metric_cols = st.columns(3)
    with metric_cols[0]:
        st.metric(
            "æ•°æ®æ—¶é—´èŒƒå›´",
            f"{hotspot_data['äº‹æ•…æ—¶é—´'].min().strftime('%Y-%m-%d')} è‡³ {hotspot_data['äº‹æ•…æ—¶é—´'].max().strftime('%Y-%m-%d')}",
        )
    with metric_cols[1]:
        st.metric(
            "äº‹æ•…ç±»å‹åˆ†å¸ƒ",
            f"è´¢æŸ: {len(hotspot_data[hotspot_data['äº‹æ•…ç±»å‹'] == 'è´¢æŸ'])}èµ·",
        )
    with metric_cols[2]:
        st.metric("æ¶‰åŠåŒºåŸŸ", f"{hotspot_data['æ‰€åœ¨è¡—é“'].nunique()}ä¸ªè¡—é“")

    st.subheader("ğŸ”§ åˆ†æå‚æ•°è®¾ç½®")
    settings_cols = st.columns(3)
    with settings_cols[0]:
        time_window = st.selectbox(
            "ç»Ÿè®¡æ—¶é—´çª—å£",
            options=["7D", "15D", "30D"],
            index=0,
            key="hotspot_window",
        )
    with settings_cols[1]:
        min_accidents = st.number_input(
            "æœ€å°äº‹æ•…æ•°", min_value=1, max_value=50, value=3, key="hotspot_min_accidents"
        )
    with settings_cols[2]:
        top_n = st.slider("æ˜¾ç¤ºçƒ­ç‚¹æ•°é‡", min_value=3, max_value=20, value=8, key="hotspot_top_n")

    if not st.button("ğŸš€ å¼€å§‹çƒ­ç‚¹åˆ†æ", type="primary"):
        return

    with st.spinner("æ­£åœ¨åˆ†æäº‹æ•…çƒ­ç‚¹åˆ†å¸ƒâ€¦"):
        hotspots = analyze_hotspot_frequency(hotspot_data, time_window=time_window)
        hotspots = hotspots[hotspots["accident_count"] >= min_accidents]

        if hotspots.empty:
            st.warning("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„äº‹æ•…çƒ­ç‚¹æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰å‚æ•°ã€‚")
            return

        hotspots_with_risk = calculate_hotspot_risk_score(hotspots.head(top_n * 3))
        top_hotspots = hotspots_with_risk.head(top_n)

    st.subheader("ğŸ“Š äº‹æ•…å¤šå‘è·¯å£æ’åï¼ˆå‰{0}ä¸ªï¼‰".format(top_n))
    display_columns = {
        "accident_count": "ç´¯è®¡äº‹æ•…æ•°",
        "recent_count": "è¿‘æœŸäº‹æ•…æ•°",
        "trend_ratio": "è¶‹åŠ¿æ¯”ä¾‹",
        "main_accident_type": "ä¸»è¦ç±»å‹",
        "main_intersection_type": "è·¯å£ç±»å‹",
        "risk_score": "é£é™©è¯„åˆ†",
        "risk_level": "é£é™©ç­‰çº§",
    }
    display_df = top_hotspots[list(display_columns.keys())].rename(columns=display_columns)
    styled_df = display_df.style.format({"è¶‹åŠ¿æ¯”ä¾‹": "{:.2f}", "é£é™©è¯„åˆ†": "{:.1f}"}).background_gradient(
        subset=["é£é™©è¯„åˆ†"], cmap="Reds"
    )
    st.dataframe(styled_df, use_container_width=True)

    st.subheader("ğŸ¯ é’ˆå¯¹æ€§ç­–ç•¥å»ºè®®")
    strategies = generate_hotspot_strategies(top_hotspots, time_period="æœ¬å‘¨")
    for index, strategy_info in enumerate(strategies, start=1):
        message = f"**{index}. {strategy_info['strategy']}**"
        risk_level = strategy_info["risk_level"]
        if risk_level == "é«˜é£é™©":
            st.error(f"ğŸš¨ {message}")
        elif risk_level == "ä¸­é£é™©":
            st.warning(f"âš ï¸ {message}")
        else:
            st.info(f"âœ… {message}")

    st.subheader("ğŸ“ˆ æ•°æ®åˆ†æå¯è§†åŒ–")
    chart_cols = st.columns(2)
    with chart_cols[0]:
        fig_hotspots = px.bar(
            top_hotspots.head(10),
            x=top_hotspots.head(10).index,
            y=["accident_count", "recent_count"],
            title="äº‹æ•…é¢‘æ¬¡TOP10åˆ†å¸ƒ",
            labels={"value": "äº‹æ•…æ•°é‡", "variable": "ç±»å‹", "index": "è·¯å£åç§°"},
            barmode="group",
        )
        fig_hotspots.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_hotspots, use_container_width=True)

    with chart_cols[1]:
        risk_distribution = top_hotspots["risk_level"].value_counts()
        fig_risk = px.pie(
            values=risk_distribution.values,
            names=risk_distribution.index,
            title="é£é™©ç­‰çº§åˆ†å¸ƒ",
            color_discrete_map={"é«˜é£é™©": "red", "ä¸­é£é™©": "orange", "ä½é£é™©": "green"},
        )
        st.plotly_chart(fig_risk, use_container_width=True)

    st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")
    download_cols = st.columns(2)
    with download_cols[0]:
        hotspot_csv = top_hotspots.to_csv().encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ ä¸‹è½½çƒ­ç‚¹æ•°æ®CSV",
            data=hotspot_csv,
            file_name=f"accident_hotspots_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
        )

    with download_cols[1]:
        serializable = serialise_datetime_columns(
            top_hotspots.reset_index(),
            columns=[col for col in top_hotspots.columns if "time" in col or "date" in col],
        )
        report_payload = {
            "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "time_window": time_window,
            "data_source": accident_source_name or "äº‹æ•…æ•°æ®",
            "total_records": int(len(hotspot_data)),
            "analysis_parameters": {"min_accidents": int(min_accidents), "top_n": int(top_n)},
            "top_hotspots": serializable.to_dict("records"),
            "recommended_strategies": strategies,
            "summary": {
                "high_risk_count": int((top_hotspots["risk_level"] == "é«˜é£é™©").sum()),
                "medium_risk_count": int((top_hotspots["risk_level"] == "ä¸­é£é™©").sum()),
                "total_analyzed_locations": int(len(hotspots)),
                "most_dangerous_location": top_hotspots.index[0]
                if len(top_hotspots)
                else "æ— ",
            },
        }
        st.download_button(
            "ğŸ“„ ä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š",
            data=json.dumps(report_payload, ensure_ascii=False, indent=2),
            file_name=f"hotspot_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
            mime="application/json",
        )

    with st.expander("ğŸ“‹ æŸ¥çœ‹åŸå§‹æ•°æ®é¢„è§ˆ"):
        preview_cols = ["äº‹æ•…æ—¶é—´", "æ‰€åœ¨è¡—é“", "äº‹æ•…ç±»å‹", "äº‹æ•…å…·ä½“åœ°ç‚¹", "é“è·¯ç±»å‹"]
        preview_df = hotspot_data[preview_cols].copy()
        st.dataframe(preview_df.head(10), use_container_width=True)

